# @file ExportToParquet.R
#
#
# Copyright 2021 Observational Health Data Sciences and Informatics
#
# This file is part of AresIndexer
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#' Export to Parquet
#' @name exportToParquet
#'
#' @details Exports tables from DuckDB database generated by the Achilles package
#'
#' @param sourceFolders A vector of folder locations that contain the files
#' exported from Achilles in the ARES Option format (Achilles::exportAO)
#'
#'
#'
#'
#'
#' @import DBI
#' @import duckdb
#' @import dplyr
#'
#' @export
exportToParquet <- function(sourceFolders) {
  releaseFolders <- list.dirs(sourceFolders, recursive = F)
  for (releaseFolder in releaseFolders) {
    exportReleaseToParquet(releaseFolder)
  }
}

#' Export Release to Parquet
#' @name exportReleaseToParquet
#'
#' @details Exports tables from DuckDB database generated by the Achilles package
#'
#' @param releaseFolder Release folder containing the files exported from
#' Achilles in the ARES Option format (Achilles::exportAO)
#'
#' @import DBI
#' @import duckdb
#' @import dplyr
#'
#' @export
exportReleaseToParquet <- function(releaseFolder) {
  print(paste0("Processing release folder ", releaseFolder))
  databaseLocation <- file.path(releaseFolder, "concepts", "data.duckdb")
  duckdbCon <- duckdb::dbConnect(
    duckdb::duckdb(dbdir = databaseLocation),
    read_only = TRUE)
  on.exit(DBI::dbDisconnect(duckdbCon, shutdown = TRUE), add = TRUE)
  tableNames <- duckdb::dbListTables(duckdbCon, schema = "concepts")
  sort_column <- "CONCEPT_ID"

  for (tableName in tableNames) {
    table <- tbl(duckdbCon, DBI::Id(schema = "concepts", table = tableName))
    table <- as.data.frame(table)

    if (sort_column %in% colnames(table)) {
      sort_col_index <- which(colnames(table) == sort_column)
      table[[sort_col_index]] <- as.integer(table[[sort_col_index]])
      table <- table[order(table[[sort_col_index]]),]
    } else {
      warning(paste("Sorting column '", sort_column, "' not found in the table. Skipping sorting.", sep = ""))
    }

    filename <- paste0(tableName, ".parquet")
    parquetPath <- file.path(releaseFolder, "concepts", filename)
    arrow::write_parquet(
      table,
      version = "2.6",
      parquetPath,
      compression = "gzip",
      compression_level = 5,
      use_dictionary = TRUE,
      write_statistics = TRUE,
      chunk_size = 8 * 1024
    )

    cat("Processed:", tableName, "\n")
  }
}
